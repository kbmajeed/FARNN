2016-06-08 13:57:08[outputs/rnn,model=rnn Deep Head Motion Control]:  [program started on Wed Jun  8 13:57:08 2016] 
2016-06-08 13:57:08[outputs/rnn,model=rnn Deep Head Motion Control]:  [command line arguments] 
2016-06-08 13:57:08[outputs/rnn,model=rnn Deep Head Motion Control]:  coefL2 0.2 
2016-06-08 13:57:08[outputs/rnn,model=rnn Deep Head Motion Control]:  trainStop 0.5 
2016-06-08 13:57:08[outputs/rnn,model=rnn Deep Head Motion Control]:  tau 1 
2016-06-08 13:57:08[outputs/rnn,model=rnn Deep Head Motion Control]:  rundir outputs/rnn,model=rnn 
2016-06-08 13:57:08[outputs/rnn,model=rnn Deep Head Motion Control]:  learningRate 0.1 
2016-06-08 13:57:08[outputs/rnn,model=rnn Deep Head Motion Control]:  rho 5 
2016-06-08 13:57:08[outputs/rnn,model=rnn Deep Head Motion Control]:  data data/soft_robot.mat 
2016-06-08 13:57:08[outputs/rnn,model=rnn Deep Head Motion Control]:  optimizer mse 
2016-06-08 13:57:08[outputs/rnn,model=rnn Deep Head Motion Control]:  m_eps 0.01 
2016-06-08 13:57:08[outputs/rnn,model=rnn Deep Head Motion Control]:  model rnn 
2016-06-08 13:57:08[outputs/rnn,model=rnn Deep Head Motion Control]:  seed 123 
2016-06-08 13:57:08[outputs/rnn,model=rnn Deep Head Motion Control]:  maxIter 10000 
2016-06-08 13:57:08[outputs/rnn,model=rnn Deep Head Motion Control]:  silent true 
2016-06-08 13:57:08[outputs/rnn,model=rnn Deep Head Motion Control]:  rnnlearningRate 0.1 
2016-06-08 13:57:08[outputs/rnn,model=rnn Deep Head Motion Control]:  hiddenSize table: 0x40195cc0 
2016-06-08 13:57:08[outputs/rnn,model=rnn Deep Head Motion Control]:  dir outputs 
2016-06-08 13:57:08[outputs/rnn,model=rnn Deep Head Motion Control]:  sigma 0.01 
2016-06-08 13:57:08[outputs/rnn,model=rnn Deep Head Motion Control]:  netdir network 
2016-06-08 13:57:08[outputs/rnn,model=rnn Deep Head Motion Control]:  coefL1 0.1 
2016-06-08 13:57:08[outputs/rnn,model=rnn Deep Head Motion Control]:  plot false 
2016-06-08 13:57:08[outputs/rnn,model=rnn Deep Head Motion Control]:  l_eps 0.05 
2016-06-08 13:57:08[outputs/rnn,model=rnn Deep Head Motion Control]:  momentum 0.9 
2016-06-08 13:57:08[outputs/rnn,model=rnn Deep Head Motion Control]:  gpu 0 
2016-06-08 13:57:08[outputs/rnn,model=rnn Deep Head Motion Control]:  Correction 60 
2016-06-08 13:57:08[outputs/rnn,model=rnn Deep Head Motion Control]:  print false 
2016-06-08 13:57:08[outputs/rnn,model=rnn Deep Head Motion Control]:  batchSize 6 
2016-06-08 13:57:08[outputs/rnn,model=rnn Deep Head Motion Control]:  dropout true 
2016-06-08 13:57:08[outputs/rnn,model=rnn Deep Head Motion Control]:  backend cudnn 
2016-06-08 13:57:08[outputs/rnn,model=rnn Deep Head Motion Control]:  learningRateDecay 1e-06 
2016-06-08 13:57:08[outputs/rnn,model=rnn Deep Head Motion Control]:  dropoutProb 0.5 
2016-06-08 13:57:08[outputs/rnn,model=rnn Deep Head Motion Control]:  [----------------------] 
2016-06-08 13:57:08[outputs/rnn,model=rnn Deep Head Motion Control]:   
2016-06-08 13:57:08[outputs/rnn,model=rnn Deep Head Motion Control]:  ==> fundamental initializations 
2016-06-08 13:57:09[outputs/rnn,model=rnn Deep Head Motion Control]:  
System has 1 gpu(s). Code is running on GPU: 1 
2016-06-08 13:57:09[outputs/rnn,model=rnn Deep Head Motion Control]:  ==> Parsing raw data 
2016-06-08 13:57:09[outputs/rnn,model=rnn Deep Head Motion Control]:  ==> Data Pre-processing 
2016-06-08 13:57:09[outputs/rnn,model=rnn Deep Head Motion Control]:  ==> Determining input-output model order parameters 
2016-06-08 13:57:09[outputs/rnn,model=rnn Deep Head Motion Control]:  ==> Setting up neural network parameters 
2016-06-08 13:57:09[outputs/rnn,model=rnn Deep Head Motion Control]:  Network Table
 
2016-06-08 13:57:09[outputs/rnn,model=rnn Deep Head Motion Control]:  nn.Repeater {
  [  input,    input,  ...,  input  ]
       V         V             V     
  nn.Recursor @ nn.Sequential {
    [input -> (1) -> (2) -> (3) -> (4) -> output]
    (1): nn.Sequential {
      [input -> (1) -> (2) -> (3) -> output]
      (1): nn.Linear(1 -> 1)
      (2): nn.ReLU
      (3): nn.Linear(1 -> 6)
    }
    (2): nn.Sigmoid
    (3): nn.Recurrent {
      [{input(t), output(t-1)} -> (1) -> (2) -> (3) -> output(t)]
      (1):  {
        input(t)
          |`-> (t==0): nn.Add
          |`-> (t~=0): nn.Linear(6 -> 6)
        output(t-1)
          |`-> nn.Linear(6 -> 6)
      }
      (2): nn.CAddTable
      (3): nn.ReLU
    }
    (4): nn.Linear(6 -> 1)
  }
       V         V             V     
  [output(1),output(2),...,output(6)]
} 
2016-06-08 13:57:09[outputs/rnn,model=rnn Deep Head Motion Control]:  ==> configuring optimizer
 
2016-06-08 13:57:09[outputs/rnn,model=rnn Deep Head Motion Control]:  ==> defining training procedure 
2016-06-08 13:57:09[outputs/rnn,model=rnn Deep Head Motion Control]:  <trainer> on training set:  
2016-06-08 13:57:09[outputs/rnn,model=rnn Deep Head Motion Control]:  <trainer> online epoch # 1 [batchSize = 6]
 
2016-06-08 13:59:07[outputs/rnn,model=rnn Deep Head Motion Control]:  <trainer> time to learn 1 sample = 11.78159353868ms 
2016-06-08 13:59:07[outputs/rnn,model=rnn Deep Head Motion Control]:  <trainer> on testing Set: 
2016-06-08 14:00:25[outputs/rnn,model=rnn Deep Head Motion Control]:  <trainer> on training set:  
2016-06-08 14:00:25[outputs/rnn,model=rnn Deep Head Motion Control]:  <trainer> online epoch # 2 [batchSize = 6]
 
2016-06-08 14:00:25[outputs/rnn,model=rnn Deep Head Motion Control]:  Epoch 2, iter = 1667, Loss = 0.621600  
2016-06-08 14:02:27[outputs/rnn,model=rnn Deep Head Motion Control]:  <trainer> time to learn 1 sample = 12.102257601673ms 
2016-06-08 14:02:27[outputs/rnn,model=rnn Deep Head Motion Control]:  <trainer> on testing Set: 
2016-06-08 14:03:43[outputs/rnn,model=rnn Deep Head Motion Control]:  <trainer> on training set:  
2016-06-08 14:03:43[outputs/rnn,model=rnn Deep Head Motion Control]:  <trainer> online epoch # 3 [batchSize = 6]
 
2016-06-08 14:03:43[outputs/rnn,model=rnn Deep Head Motion Control]:  Epoch 3, iter = 1667, Loss = 0.516716  
2016-06-08 14:05:43[outputs/rnn,model=rnn Deep Head Motion Control]:  <trainer> time to learn 1 sample = 11.908806163481ms 
2016-06-08 14:05:43[outputs/rnn,model=rnn Deep Head Motion Control]:  <trainer> on testing Set: 
2016-06-08 14:06:57[outputs/rnn,model=rnn Deep Head Motion Control]:  <trainer> on training set:  
2016-06-08 14:06:57[outputs/rnn,model=rnn Deep Head Motion Control]:  <trainer> online epoch # 4 [batchSize = 6]
 
2016-06-08 14:06:57[outputs/rnn,model=rnn Deep Head Motion Control]:  Epoch 4, iter = 1667, Loss = 2.169104  
2016-06-08 14:09:04[outputs/rnn,model=rnn Deep Head Motion Control]:  <trainer> time to learn 1 sample = 12.560666826773ms 
2016-06-08 14:09:04[outputs/rnn,model=rnn Deep Head Motion Control]:  <trainer> on testing Set: 
2016-06-08 14:10:17[outputs/rnn,model=rnn Deep Head Motion Control]:  <trainer> on training set:  
2016-06-08 14:10:17[outputs/rnn,model=rnn Deep Head Motion Control]:  <trainer> online epoch # 5 [batchSize = 6]
 
2016-06-08 14:10:17[outputs/rnn,model=rnn Deep Head Motion Control]:  Epoch 5, iter = 1667, Loss = 0.347666  
